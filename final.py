import re
import time
from datetime import datetime, timedelta, UTC
import requests as rq
from bs4 import BeautifulSoup
from curl_cffi import requests as curl_requests # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã Forebet

# ===============================
# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram
# ===============================
# –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–º–µ–Ω–∏ —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å–≤–æ–∏ —Ä–µ–∞–ª—å–Ω—ã–µ.
TOKEN = "8353200396:AAEYPs8RmdEUfsK6lG1U3kve3fjL-oAIR3I"
CHAT_ID = 293637253

def send_telegram_message(text):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram —Å HTML-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML"}
    try:
        response = rq.post(url, data=payload, timeout=20)
        if not response.ok:
            print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram:", response.text)
    except Exception as e:
        print("–û—à–∏–±–∫–∞ HTTP –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram:", e)

# ===============================
# üîπ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ===============================
def normalize_team_name(name: str):
    """–û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –∏ —É–±–∏—Ä–∞–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞"""
    name = re.sub(r'[^a-zA-Z0-9\s\-]', '', str(name)).lower()
    words = name.split()
    ignore = {
        'town', 'city', 'county', 'borough', 'united', 'district', 'state',
        'fc', 'afc', 'cf', 'sc', 'ac', 'bc', 'rc', 'cd', 'sd', 'ud',
        'fk', 'nk', 'ks',
        'u17', 'u18', 'u19', 'u20', 'u21', 'u23',
        'b', 'ii', 'reserve', 'reserves',
        'club', 'team', 'sporting',
        'sv', 'tsv', 'vfb', 'vfl', 'sg', 'spvgg'
    }
    return [w for w in words if w not in ignore and len(w) > 2]

def teams_match(z_team: str, f_team: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É"""
    z_words = normalize_team_name(z_team)
    f_words = normalize_team_name(f_team)
    return any(zw in f_words for zw in z_words)

# ===============================
# üîπ –ü–∞—Ä—Å–∏–Ω–≥ Zulubet
# ===============================
def parse_zulubet():
    """–ü–∞—Ä—Å–∏—Ç –º–∞—Ç—á–∏ —Å Zulubet, —Ñ–∏–ª—å—Ç—Ä—É—è –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ >= 60%."""
    url = "https://www.zulubet.com/"
    headers = {"User-Agent": "Mozilla/5.0"}
    results = []
    
    try:
        response = rq.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ Zulubet: {e}")
        return []

    main_table = soup.select_one("table.content_tables.main_table")
    if not main_table:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É –º–∞—Ç—á–µ–π –Ω–∞ Zulubet.")
        return []

    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤—ã–µ 2 —Å—Ç—Ä–æ–∫–∏)
    rows = main_table.find_all("tr")[2:]

    for row in rows:
        try:
            cells = row.find_all("td")
            if len(cells) < 6:
                continue

            # 1. –í—Ä–µ–º—è
            script_tag = cells[0].find("script")
            raw_time = (
                script_tag.string.strip()
                .replace("mf_usertime('", "")
                .replace("');", "")
                if script_tag else "?"
            )
            try:
                # –í Zulubet –≤—Ä–µ–º—è –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ UTC-1 (–ø–æ–ø—Ä–∞–≤–∫–∞ –Ω–∞ —á–∞—Å)
                dt = datetime.strptime(raw_time, "%m/%d/%Y, %H:%M") + timedelta(hours=1)
                time_str = dt.strftime("%d/%m %H:%M")
            except:
                time_str = raw_time

            # 2. –ú–∞—Ç—á (–∫–æ–º–∞–Ω–¥—ã)
            match_a = cells[1].find("a")
            match = match_a.text.strip() if match_a else "?"

            # 3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            def extract_percent(text):
                # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –∏–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                return int(text.split(":")[1].replace("%", "").strip())
                
            p1 = extract_percent(cells[3].text)
            px = extract_percent(cells[4].text)
            p2 = extract_percent(cells[5].text)

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            if p1 >= 60 or px >= 60 or p2 >= 60:
                parts = re.split(r'\s*-\s*', match)
                home = parts[0].strip()
                away = parts[1].strip() if len(parts) > 1 else "?"
                results.append({
                    "time": time_str,
                    "home": home,
                    "away": away,
                    "text": f"{time_str} ‚öΩÔ∏è {match} ¬†{p1}-{px}-{p2}"
                })

        except Exception as e:
            # –ü–µ—á–∞—Ç–∞–µ–º –æ—à–∏–±–∫—É, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞—Ä—Å–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏
            # print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ Zulubet: {e}") 
            continue

    return results

# ===============================
# üîπ –ü–∞—Ä—Å–µ—Ä Forebet
# ===============================
# –ö–µ—à –∏ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ Cron Job –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Å –Ω—É–ª—è
# –∏ –¥–æ–ª–∂–µ–Ω –≤—Å–µ–≥–¥–∞ –ø–æ–ª—É—á–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.

def fetch_forebet():
    """–ü–∞—Ä—Å–∏—Ç –º–∞—Ç—á–∏ Forebet –∑–∞ —Å–µ–≥–æ–¥–Ω—è –∏ –∑–∞–≤—Ç—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º API –∏ HTML."""
    results = []
    urls = [
        ("today", "https://www.forebet.com/en/football-tips-and-predictions-for-today"),
        ("tomorrow", "https://www.forebet.com/en/football-tips-and-predictions-for-tomorrow")
    ]

    session = curl_requests.Session()

    for desc, main_url in urls:
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º HTML –¥–ª—è –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö —Å—á–µ—Ç–æ–≤ (BeautifulSoup)
            resp_main = session.get(main_url, impersonate="chrome110", timeout=20)
            resp_main.raise_for_status()
            soup = BeautifulSoup(resp_main.text, "html.parser")
            score_divs = soup.find_all("div", class_="ex_sc tabonly")

            # 2. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –º–∞—Ç—á–∞—Ö –∏ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (API)
            api_url = "https://www.forebet.com/scripts/getrs.php"
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º datetime.now(UTC) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Python 3.11+
            if desc == "today":
                date_str = datetime.now(UTC).strftime("%Y-%m-%d")
            else:
                date_str = (datetime.now(UTC) + timedelta(days=1)).strftime("%Y-%m-%d")

            params = {
                "ln": "en", "tp": "1x2", "in": date_str,
                "ord": "0", "tz": "+60", "tzs": "0", "tze": "0"
            }

            resp_api = session.get(api_url, params=params, impersonate="chrome110", timeout=20)
            resp_api.raise_for_status()
            json_data = resp_api.json()

            if not json_data or not json_data[0]:
                print(f"{desc.capitalize()}: –º–∞—Ç—á–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                continue

            matches = json_data[0]

            for i, match in enumerate(matches):
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
                date_time = match.get("DATE_BAH", "N/A").split(' ')
                date_match = date_time[0]
                time_match = date_time[1][:5] if len(date_time) > 1 else "N/A"

                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                host = match.get("HOST_NAME", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                guest = match.get("GUEST_NAME", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                p1 = int(match.get("Pred_1", 0))
                px = int(match.get("Pred_X", 0))
                p2 = int(match.get("Pred_2", 0))

                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–æ–≥–æ —Å—á–µ—Ç–∞
                forecast_score = score_divs[i].get_text(strip=True) if i < len(score_divs) else ""

                results.append({
                    "time": f"{date_match} {time_match}",
                    "home": host,
                    "away": guest,
                    "p1": p1, "px": px, "p2": p2,
                    "score": forecast_score
                })

            print(f"‚úî {desc.capitalize()}: —Å–æ–±—Ä–∞–Ω–æ –º–∞—Ç—á–µ–π {len(matches)}")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Forebet ({desc}): {e}")
            continue

    return results

# ===============================
# üîÅ –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ Cron Job
# ===============================
def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –∫–∞–∫ –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è."""
    print("–°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –∫–∞–∫ Cron Job. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–∞—Ä—Å–∏–Ω–≥ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ.")

    forebet_results = fetch_forebet()
    zulubet_results = parse_zulubet()

    # üîπ –§–∏–ª—å—Ç—Ä Forebet –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ ‚â• 60
    forebet_results_filtered = [
        f for f in forebet_results if f['p1'] >= 60 or f['px'] >= 60 or f['p2'] >= 60
    ]

    print(f"\nZulubet: –Ω–∞–π–¥–µ–Ω–æ {len(zulubet_results)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–∞—Ç—á–µ–π (–ø–æ –ø–æ—Ä–æ–≥—É).")
    print(f"Forebet –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ ‚â•60: {len(forebet_results_filtered)} –º–∞—Ç—á–µ–π")

    combined_matches = []
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    for z in zulubet_results:
        # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–æ–º–∞–Ω–¥–∞–º
        f_matches = [
            f for f in forebet_results_filtered 
            if teams_match(z["home"], f["home"]) or teams_match(z["away"], f["away"])
        ]
        
        if f_matches:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –±–ª–æ–∫–∞ —Å –º–∞—Ç—á–µ–º Zulubet
            z_text_html = f"<b>ZULUBET: {z['text']}</b>"
            combined_matches.append(z_text_html)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–≤—à–∏–µ –º–∞—Ç—á–∏ Forebet
            for f in f_matches:
                line = (
                    f"FOR: {f['time']} {f['home']} vs {f['away']} ¬†"
                    f"P: {f['p1']}-{f['px']}-{f['p2']} ¬†"
                    f"–°—á–µ—Ç: {f['score']}"
                )
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è
                is_full_match = teams_match(z["home"], f["home"]) and teams_match(z["away"], f["away"])
                
                if is_full_match:
                    combined_matches.append(f"üî• {line}")
                else:
                    combined_matches.append(line)
            
            combined_matches.append("")  # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏

    if combined_matches:
        final_message = "\n".join(combined_matches)
        send_telegram_message("üîî –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π! üîî\n\n" + final_message)
        print("‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω—ã –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã.")
    else:
        print("‚Äî –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç.")

if __name__ == "__main__":
    main()
